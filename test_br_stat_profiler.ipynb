{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**br_stat_profiler - Help Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--version] [-i <GATKReport [stdin]>]\n",
      "                             [-o <*.csv [stdout]>] [-lg <*.* [stderr]>]\n",
      "                             [-mq <int min=1 [1]>] [-mxq <int max=100 [100]>]\n",
      "                             [-eo <int 1 to 10 [4]>] [-sb <int 1 to 10 [4]>]\n",
      "                             [-cb <int 1 to 15 [10]>] [-mic <int [1]>]\n",
      "                             [-mxc <int [150]>] [-nan <float [None]>] [-sym]\n",
      "                             [-z] [-ct <choices [cntxt]>] [-co <float [-20]>]\n",
      "                             [-nW] [-wN <int [2]>] [-wRY <int [3]>]\n",
      "                             [-wMSW <int [3]>] [-wBDHV <int [3]>]\n",
      "                             [-V <choices [info]>] [-xRG]\n",
      "\n",
      "br_stat_profiler (v1.2) - Converts GATK (V4.4.0.0) BaseRecalibrator stat\n",
      "report into profiles that can be compared/clustered downstream. It generates a\n",
      "separate profile for each ReadGroup in the stat report and tabulates them for\n",
      "easy analysis. The profiles can be saved in a CSV format or streamed as output\n",
      "for further processing.\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --version             show program's version number and exit\n",
      "  -i <GATKReport [stdin]>, --infile <GATKReport [stdin]>\n",
      "                        Path for file, or stdin with Existing GATK (v4.4.0.0)\n",
      "                        BaseRecalibrator report. (default=stdin)\n",
      "  -o <*.csv [stdout]>, --outfile <*.csv [stdout]>\n",
      "                        Path of NON-EXISTING .csv file for the generated\n",
      "                        profile. (default=stdout)\n",
      "  -lg <*.* [stderr]>, --log_file <*.* [stderr]>\n",
      "                        NON-EXISTING file for profile metadata .\n",
      "                        (default=<ipykernel.iostream.OutStream object at\n",
      "                        0x7fe56b6a19f0>)\n",
      "  -mq <int min=1 [1]>, --min_score <int min=1 [1]>\n",
      "                        Minimal QualityScore value for profiling (default=1)\n",
      "  -mxq <int max=100 [100]>, --max_score <int max=100 [100]>\n",
      "                        Maximal QualityScore value for profiling (default=100)\n",
      "  -eo <int 1 to 10 [4]>, --min_err_observed <int 1 to 10 [4]>\n",
      "                        Minimal Number of Errornous Observations for profiling\n",
      "                        (default=100)\n",
      "  -sb <int 1 to 10 [4]>, --scr_bin_count <int 1 to 10 [4]>\n",
      "                        # of bins to divide the QualityScore values (The\n",
      "                        profiler further averages the QError rate in each\n",
      "                        bin). (default=4)\n",
      "  -cb <int 1 to 15 [10]>, --cyc_bin_count <int 1 to 15 [10]>\n",
      "                        The # of bins to divide reading cycle covariate so\n",
      "                        that reads are cut into equal fragments. QEerror is\n",
      "                        averaged for each cycle bin (=fragment). (default=10)\n",
      "  -mic <int [1]>, --min_cyc <int [1]>\n",
      "                        In cycles profiling, The start position in the read.\n",
      "                        Irrelevant for context profiling. (default=1)\n",
      "  -mxc <int [150]>, --max_cyc <int [150]>\n",
      "                        In cycles profiling, last position in the read.\n",
      "                        Irrelevant for context profiling. (default=150)\n",
      "  -nan <float [None]>, --nan_rep <float [None]>\n",
      "                        Optional Character filler for missing/cutoffed values.\n",
      "  -sym, --qerr_cutoff_both_sides\n",
      "                        Symmetrical qerr cutoff. For example, for cutoff=3,\n",
      "                        QErrors below 3 and above -3 are cut (default=False)\n",
      "  -z, --zscore          ZScoring the final profile (preformed after the QErr\n",
      "                        cuttoff if requested). None values are ignored\n",
      "                        (default=False)\n",
      "  -ct <choices [cntxt]>, --cov_type <choices [cntxt]>\n",
      "                        Covariats type to profile QErrors. Profiling may take\n",
      "                        either the QErrors context or cycle or both (context +\n",
      "                        cycle). options=['cntxt', 'cyc', 'cntxt_cyc'],\n",
      "                        (default=cntxt)\n",
      "  -co <float [-20]>, --qerr_cutoff <float [-20]>\n",
      "                        Cutoff for Qerror (for removal of an hypothetical\n",
      "                        noise) (default=-20)\n",
      "  -nW, --no_wobble      Do not calculate wobbled k-mers statistics - Include\n",
      "                        only k-mers with {A,C,G,T} (default=False)\n",
      "  -wN <int [2]>, --max_wob_N_occ <int [2]>\n",
      "                        Maximal occurence of wobble positions N in the k-mers\n",
      "                        statistic calculation (default=2)\n",
      "  -wRY <int [3]>, --max_wob_R_Y_occ <int [3]>\n",
      "                        Maximal occurence of wobble positions R (Purines) and\n",
      "                        Y (Pyrmidines) in the k-mers statistic calculation\n",
      "                        (default=3)\n",
      "  -wMSW <int [3]>, --max_wob_M_S_W_occ <int [3]>\n",
      "                        Maximal occurence of wobble positions M, S, W (with\n",
      "                        both Purine and Pyrmidine) in the k-mers statistic\n",
      "                        calculation (default=3)\n",
      "  -wBDHV <int [3]>, --max_wob_B_D_H_V_occ <int [3]>\n",
      "                        Maximal occurence of wobble positions B,D,H,V (without\n",
      "                        A or C or G or T respectfully) in the k-mers statistic\n",
      "                        calculation (default=2)\n",
      "  -V <choices [info]>, --verbose <choices [info]>\n",
      "                        Verbosity level. In a non-silent mode (default), msgs\n",
      "                        are streamed to stderr (default) or logfile.\n",
      "                        options=['info', 'silent', 'debug'], (default=info)\n",
      "  -xRG, --extract_read_group\n",
      "                        Extract read group name - from a \":\" delimited\n",
      "                        ReadGroup String (first token) (default=False)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ido/miniconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3513: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from user_args import load_parser, check_args\n",
    "\n",
    "cmd = f\"--help\"\n",
    "parser = load_parser()\n",
    "args = parser.parse_args(cmd.split())\n",
    "adict = check_args(args) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**br_stat_profiling**<br>\n",
    "Setting: qerr_cutoff  is turned off, 2 wobble_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0m:0s (  Init   ) - 2023-06-17 23:01:43,799 - INFO - \n",
      " version                :\t1.1\n",
      "infile                 :\t<_io.TextIOWrapper name='./data/test_bqsr/pre-LUAD-02_all_chrs_wo_Y_MT.bam.context4.recal_data.table' mode='r' encoding='UTF-8'>\n",
      "outfile                :\t<_io.TextIOWrapper name='./outfiles/first_profile_num.csv' mode='x' encoding='UTF-8'>\n",
      "log_file               :\t<ipykernel.iostream.OutStream object at 0x7f7b12c559c0>\n",
      "min_score              :\t20\n",
      "max_score              :\t100\n",
      "min_err_observed       :\t100\n",
      "scr_bin_count          :\t3\n",
      "cyc_bin_count          :\t10\n",
      "min_cyc                :\t1\n",
      "max_cyc                :\t150\n",
      "nan_rep                :\tNone\n",
      "qerr_cutoff_both_sides :\tFalse\n",
      "zscore                 :\tFalse\n",
      "cov_type               :\tcntxt\n",
      "qerr_cutoff            :\t-20.0\n",
      "no_wobble              :\tFalse\n",
      "max_wob_N_occ          :\t2\n",
      "max_wob_R_Y_occ        :\t3\n",
      "max_wob_M_S_W_occ      :\t3\n",
      "max_wob_B_D_H_V_occ    :\t2\n",
      "verbose                :\tinfo\n",
      "extract_read_group     :\tTrue \n",
      "========================================\n",
      "0m:0s (+0.0009 s) - 2023-06-17 23:01:43,799 - INFO - Harvesting Arguments, 17 rows\n",
      "0m:0s (+0.0019 s) - 2023-06-17 23:01:43,801 - INFO - Harvesting Quantized, 94 rows\n",
      "0m:0s (+0.0012 s) - 2023-06-17 23:01:43,803 - INFO - Harvesting RecalTable0, 1 rows\n",
      "0m:0s (+0.0014 s) - 2023-06-17 23:01:43,804 - INFO - Harvesting RecalTable1, 28 rows\n",
      "0m:0s (+0.0016 s) - 2023-06-17 23:01:43,806 - INFO - Harvesting RecalTable2, 13940 rows\n",
      "0m:0s (+0.0174 s) - 2023-06-17 23:01:43,823 - INFO - \\--------------- Harvest Finished ----------------/\n",
      "0m:0s (+0.0078 s) - 2023-06-17 23:01:43,831 - INFO - get_full_wobbled_k_mers_list: starting\n",
      "0m:0s (+0.0500 s) - 2023-06-17 23:01:43,881 - INFO - get_full_wobbled_k_mers_list: list ready (len=35450)\n",
      "0m:0s (+0.0668 s) - 2023-06-17 23:01:43,948 - INFO - add_wobble_data: removing non-wobbled k_mers\n",
      "0m:0s (+0.0040 s) - 2023-06-17 23:01:43,952 - INFO - add_wobble_data: non-wobbled k_mer removed (len=35194)\n",
      "0m:0s (+0.0003 s) - 2023-06-17 23:01:43,952 - INFO - get_wobble_data: start\n",
      "0m:8s (+8.7425 s) - 2023-06-17 23:01:52,694 - INFO - get_wobble_data: wobbled_k_mer 2500 (7.1%)\n",
      "0m:17s (+8.7330 s) - 2023-06-17 23:02:01,427 - INFO - get_wobble_data: wobbled_k_mer 5000 (14.2%)\n",
      "0m:26s (+8.6579 s) - 2023-06-17 23:02:10,085 - INFO - get_wobble_data: wobbled_k_mer 7500 (21.3%)\n",
      "0m:34s (+8.6600 s) - 2023-06-17 23:02:18,745 - INFO - get_wobble_data: wobbled_k_mer 10000 (28.4%)\n",
      "0m:35s (+1.0086 s) - 2023-06-17 23:02:19,754 - INFO - get_wobble_data: ddf_chunk 1 concatenated\n",
      "0m:44s (+8.6438 s) - 2023-06-17 23:02:28,398 - INFO - get_wobble_data: wobbled_k_mer 12500 (35.5%)\n",
      "0m:53s (+8.7740 s) - 2023-06-17 23:02:37,172 - INFO - get_wobble_data: wobbled_k_mer 15000 (42.6%)\n",
      "1m:2s (+8.7133 s) - 2023-06-17 23:02:45,885 - INFO - get_wobble_data: wobbled_k_mer 17500 (49.7%)\n",
      "1m:10s (+8.8524 s) - 2023-06-17 23:02:54,737 - INFO - get_wobble_data: wobbled_k_mer 20000 (56.8%)\n",
      "1m:11s (+0.8391 s) - 2023-06-17 23:02:55,577 - INFO - get_wobble_data: ddf_chunk 2 concatenated\n",
      "1m:20s (+8.6742 s) - 2023-06-17 23:03:04,251 - INFO - get_wobble_data: wobbled_k_mer 22500 (63.9%)\n",
      "1m:29s (+8.7356 s) - 2023-06-17 23:03:12,986 - INFO - get_wobble_data: wobbled_k_mer 25000 (71.0%)\n",
      "1m:38s (+8.8176 s) - 2023-06-17 23:03:21,804 - INFO - get_wobble_data: wobbled_k_mer 27500 (78.1%)\n",
      "1m:46s (+8.7539 s) - 2023-06-17 23:03:30,558 - INFO - get_wobble_data: wobbled_k_mer 30000 (85.2%)\n",
      "1m:47s (+1.0342 s) - 2023-06-17 23:03:31,592 - INFO - get_wobble_data: ddf_chunk 3 concatenated\n",
      "1m:56s (+8.6065 s) - 2023-06-17 23:03:40,198 - INFO - get_wobble_data: wobbled_k_mer 32500 (92.3%)\n",
      "2m:5s (+8.7282 s) - 2023-06-17 23:03:48,927 - INFO - get_wobble_data: wobbled_k_mer 35000 (99.4%)\n",
      "2m:6s (+1.0773 s) - 2023-06-17 23:03:50,004 - INFO - get_wobble_data: ddf_chunk 4 concatenated (LAST)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddf_add_id_column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2m:6s (+0.7808 s) - 2023-06-17 23:03:50,785 - INFO - prepare_stat_df finished\n",
      "2m:7s (+0.6199 s) - 2023-06-17 23:03:51,405 - INFO - br_stat_profiler finished!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106350, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HVWKMCCXY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAAA:0:Context</th>\n",
       "      <td>-2.30995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAA:1:Context</th>\n",
       "      <td>0.046981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAA:2:Context</th>\n",
       "      <td>6.033512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAB:0:Context</th>\n",
       "      <td>0.253638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAB:1:Context</th>\n",
       "      <td>2.28898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYV:1:Context</th>\n",
       "      <td>2.759209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYV:2:Context</th>\n",
       "      <td>6.383438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYW:0:Context</th>\n",
       "      <td>-0.207327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYW:1:Context</th>\n",
       "      <td>2.993084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YYYW:2:Context</th>\n",
       "      <td>6.245432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106350 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               HVWKMCCXY\n",
       "AAAA:0:Context  -2.30995\n",
       "AAAA:1:Context  0.046981\n",
       "AAAA:2:Context  6.033512\n",
       "AAAB:0:Context  0.253638\n",
       "AAAB:1:Context   2.28898\n",
       "...                  ...\n",
       "YYYV:1:Context  2.759209\n",
       "YYYV:2:Context  6.383438\n",
       "YYYW:0:Context -0.207327\n",
       "YYYW:1:Context  2.993084\n",
       "YYYW:2:Context  6.245432\n",
       "\n",
       "[106350 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "from user_args import load_parser, check_args, UARGS\n",
    "from br_stat_profiler import preprocess_GATK_report, profile_rt\n",
    "\n",
    "RECAL_TABLE_DIR = \"./data/test_bqsr/\"\n",
    "GATK_FILE = \"pre-LUAD-02_all_chrs_wo_Y_MT.bam.context4.recal_data.table\"\n",
    "# GATK_FILE = \"HKNPC-101T.bam.GATKReport.mm_cntxt.6\"\n",
    "# GATK_FILE = \"HKNPC-101T.bam.GATKReport.mm_cntxt.4\"\n",
    "REC_TAB_FULL_PATH = RECAL_TABLE_DIR + GATK_FILE\n",
    "OUTFILE_DIR = \"./outfiles/\"\n",
    "OUTFILE = OUTFILE_DIR + \"first_profile_num.csv\"\n",
    "if os.path.exists(OUTFILE):\n",
    "    os.remove(OUTFILE)\n",
    "\n",
    "# cmd = f\"--infile {REC_TAB_FULL_PATH} -o {OUTFILE} --extract_read_group --qerr_cutoff -20 --min_score 20 --scr_bin_count 3  -ct cyc\"\n",
    "cmd = f\"--infile {REC_TAB_FULL_PATH} -o {OUTFILE} --extract_read_group --qerr_cutoff -20 --min_score 20 --scr_bin_count 3  -ct cntxt\"\n",
    "# cmd = f\"--infile {REC_TAB_FULL_PATH} -o {OUTFILE} --extract_read_group --qerr_cutoff -20 --min_score 20 --scr_bin_count 3 -ct cntxt_cyc\"\n",
    "# cmd = f\"--infile {REC_TAB_FULL_PATH} -o {OUTFILE} --extract_read_group --qerr_cutoff -20 --min_score 20 --scr_bin_count 3 -nW\"\n",
    "\n",
    "parser = load_parser()\n",
    "args = parser.parse_args(cmd.split())\n",
    "adict = check_args(args) \n",
    "\n",
    "rt2_pre_stat_df = preprocess_GATK_report(adict)\n",
    "profile = profile_rt(rt2_pre_stat_df, adict)\n",
    "with adict[UARGS.OUTFILE] as f:\n",
    "    profile.to_csv(f)\n",
    "        \n",
    "print(profile.shape)\n",
    "profile"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1:** Binning Quality Scores into 4 bins (default value of scr_bin_count argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt2_pre_stat_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2:** \n",
    "1) Calculating the Qerror (Empyrical Quality - Machine Quality) \n",
    "2) Calculating the Qerror of context with wobble positions\n",
    "3) Completing the missing values as None or zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from br_stat_profiler import prepare_stat_df\n",
    "from constants import RC_TAB2\n",
    "cntxt_rt2_stat_df = prepare_stat_df(rt2_pre_stat_df, RC_TAB2.CNTXT_COV, adict)\n",
    "cntxt_rt2_stat_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QErrors Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cntxt_rt2_stat_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m cutoff \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m      8\u001b[0m bins_count \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[0;32m----> 9\u001b[0m stat_df \u001b[39m=\u001b[39m cntxt_rt2_stat_df\n\u001b[1;32m     10\u001b[0m data \u001b[39m=\u001b[39m stat_df[RT2_STAT\u001b[39m.\u001b[39mBIN_AVG_QLTY_ERR_COL]\n\u001b[1;32m     12\u001b[0m \u001b[39m# Plotting the histogram\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cntxt_rt2_stat_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from constants import RT2_STAT\n",
    "# Assuming you have a dataframe called 'df' with columns 'A', 'B', and 'C'\n",
    "cutoff = 3\n",
    "bins_count = 40\n",
    "stat_df = cntxt_rt2_stat_df\n",
    "data = stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL]\n",
    "\n",
    "# Plotting the histogram\n",
    "counts, bins, patches = plt.hist(data, bins=bins_count)  # Adjust the number of bins as needed\n",
    "\n",
    "for i in range(len(bins)-1):\n",
    "    if bins[i] <= 0:\n",
    "        patches[i].set_facecolor('tomato')\n",
    "    else:\n",
    "        patches[i].set_facecolor('cornflowerblue')\n",
    "\n",
    "# plt.axvline(x=cutoff, color='black', linestyle='--',linewidth=1.5)\n",
    "# plt.axvline(x=-cutoff, color='black', linestyle='--')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Column B')\n",
    "\n",
    "minx = math.floor(stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL].min())\n",
    "maxx =  math.ceil(stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL].max())\n",
    "xticks = np.arange(minx, maxx+1, 1)\n",
    "\n",
    "plt.xticks(xticks, rotation=45)\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QErrors Distribution - negative over positive values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from constants import RT2_STAT\n",
    "# Assuming you have a dataframe called 'df' with columns 'A', 'B', and 'C'\n",
    "cutoff = 3\n",
    "bins_count = 80\n",
    "data = cntxt_rt2_stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL]\n",
    "# Generate example data\n",
    "# data = np.random.normal(0, 1, 1000)\n",
    "\n",
    "# Create the histogram for the positive bins\n",
    "counts_pos, bins_pos, _ = plt.hist(data[data >= 0], bins=round(bins_count/2), color='cornflowerblue')\n",
    "\n",
    "# Extract the negative bins and calculate the positive mirror image\n",
    "negative_data = data[data < 0]\n",
    "mirror_data = -negative_data\n",
    "\n",
    "# Create the histogram for the mirror image of the negative bins\n",
    "counts_mirror, bins_mirror, _ = plt.hist(mirror_data, bins=bins_pos, color='tomato')\n",
    "\n",
    "plt.axvline(x=cutoff, color='black', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Find the maximum count between positive and mirrored negative bins\n",
    "max_count = max(np.max(counts_pos), np.max(counts_mirror))\n",
    "\n",
    "# Set the y-axis limit to accommodate both positive and mirrored negative bins\n",
    "plt.ylim(0, max_count)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = cntxt_rt2_stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL].isna().sum()\n",
    "total = cntxt_rt2_stat_df.shape[0]\n",
    "na_ratio = na_count/total\n",
    "print(f\"na couunt= {na_count}, total= {total}, na_ratio= {na_ratio}\")\n",
    "# NA are removed later in the profile extraction stage \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QError distribution by Score bins (covariate = Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from constants import RC_TAB2,RT2_STAT, CNTXT_RT2, RANGES\n",
    "from user_args import UARGS\n",
    "# draw a dot chart using matplotlib\n",
    "\n",
    "def score_qntl_ranges(rt2_pre_stat_df):\n",
    "    df =  rt2_pre_stat_df.groupby(RC_TAB2.RG_SCORE_BIN_COL)[RC_TAB2.QLTY_SCORE_COL].apply(lambda x: (min(x), max(x))).reset_index()\n",
    "    return df.rename(columns={RC_TAB2.QLTY_SCORE_COL: RANGES.SCORE_BIN})\n",
    "\n",
    "def jitter_list(lst, mean=0, std=0.1):\n",
    "    jittered_list = np.array(lst) + np.random.normal(mean, std, len(lst))\n",
    "    return jittered_list.tolist()\n",
    "\n",
    "\n",
    "temp_stat_df = cntxt_rt2_stat_df\n",
    "temp_stat_df = temp_stat_df.sort_values(by=[RC_TAB2.CNTXT_COV])\n",
    "y_start = math.floor(temp_stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL].min())\n",
    "y_end = math.ceil(temp_stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL].max())\n",
    "jitter_factor = (y_end - y_start) /100\n",
    "\n",
    "ranges = score_qntl_ranges(rt2_pre_stat_df)[RANGES.SCORE_BIN].unique()\n",
    "# cmap = cm.get_cmap('viridis', len(cntxt_rt2_stat_df[RC_TAB2.RG_SCORE_BIN_COL].unique()))\n",
    "cmap = cm.get_cmap('viridis', adict[UARGS.SCORE_BINS_COUNT])\n",
    "# create the scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "for i, group in temp_stat_df.groupby(RC_TAB2.RG_SCORE_BIN_COL):\n",
    "    jittered_y = jitter_list(group[RT2_STAT.BIN_AVG_QLTY_ERR_COL], 0 , jitter_factor)\n",
    "    # ax.scatter(group[CNTXT_RT2.CNTXT_COL], group[RT2_STAT.QLTY_ERR_W_AVG_COL], \n",
    "    ax.scatter(group[CNTXT_RT2.CNTXT_COL], jittered_y, \n",
    "            #    c=[cmap(i)], label=i)\n",
    "        c=[cmap(i)], label=f'{i} => {ranges[i][0]}-{ranges[i][1]}')\n",
    "\n",
    "ax.axhline(y=0, color='black', linewidth=0.8)\n",
    "ax.axhline(y=cutoff, color='red', linestyle='--', linewidth=1.5)\n",
    "ax.set_title('Context vs Weighted QErrAvg')\n",
    "ax.set_xlabel('Context')\n",
    "ax.set_ylabel('Weighted QErrAvg (Phred)')\n",
    "ax.legend(title=\"ScoreBins (0-3)\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# plt.xticks(range(cyc_rt2_stat_df[CYC_RT2.CYC_BIN_COL].min(), cyc_rt2_stat_df[CYC_RT2.CYC_BIN_COL].max()+1,2))\n",
    "\n",
    "import numpy as np\n",
    "# Y_TICKS_COUNT = 5\n",
    "# yticks = np.arange(y_start, y_end, (y_end - y_start) / (Y_TICKS_COUNT))\n",
    "YTICK_STEP = 2\n",
    "yticks = np.arange(y_start, y_end, YTICK_STEP)\n",
    "yticks = np.append(yticks, 0)\n",
    "\n",
    "plt.yticks(yticks)\n",
    "# display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from br_stat_profiler import prepare_stat_df\n",
    "from constants import RC_TAB2\n",
    "mode = RC_TAB2.CYC_COV\n",
    "cyc_rt2_stat_df = prepare_stat_df(rt2_pre_stat_df, mode, adict)\n",
    "cyc_rt2_stat_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QError Weighted Avg vs Read Cycle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from constants import RC_TAB2,RT2_STAT, CYC_RT2, RANGES\n",
    "import matplotlib.colors as mcolors\n",
    "from user_args import UARGS\n",
    "\n",
    "\n",
    "def score_qntl_ranges(rt2_pre_stat_df):\n",
    "    df =  rt2_pre_stat_df.groupby(RC_TAB2.RG_SCORE_BIN_COL)[RC_TAB2.QLTY_SCORE_COL].apply(lambda x: (min(x), max(x))).reset_index()\n",
    "    return df.rename(columns={RC_TAB2.QLTY_SCORE_COL: RANGES.SCORE_BIN})\n",
    "\n",
    "def jitter_list(lst, mean=0, std=0.1):\n",
    "    jittered_list = np.array(lst) + np.random.normal(mean, std, len(lst))\n",
    "    return jittered_list.tolist()\n",
    "\n",
    "y_start = math.floor(cyc_rt2_stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL].min())\n",
    "y_end   = math.ceil(cyc_rt2_stat_df[RT2_STAT.BIN_AVG_QLTY_ERR_COL].max())\n",
    "jitter_factor = (y_end - y_start) /100\n",
    "\n",
    "ranges = score_qntl_ranges(rt2_pre_stat_df)[RANGES.SCORE_BIN].unique()\n",
    "# cmap = cm.get_cmap('viridis', len(cyc_rt2_stat_df[RC_TAB2.RG_SCORE_BIN_COL].unique())+2)\n",
    "cmap = cm.get_cmap('viridis', adict[UARGS.SCORE_BINS_COUNT])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i, group in cyc_rt2_stat_df.groupby(RC_TAB2.RG_SCORE_BIN_COL):\n",
    "    # print(i, cmap(i))\n",
    "    jittered_y = jitter_list(group[RT2_STAT.BIN_AVG_QLTY_ERR_COL], 0 , jitter_factor)\n",
    "    ax.scatter(group[CYC_RT2.CYC_BIN_COL], jittered_y,\n",
    "        c=[cmap(i)], label=f'{i} => {ranges[i][0]}-{ranges[i][1]}')\n",
    "\n",
    "ax.axhline(y=0, color='black', linewidth=.7)\n",
    "ax.axhline(y=cutoff, color='red', linestyle='--', linewidth=1.5)\n",
    "ax.set_title('CycleBin vs Weighted QError Avg.')\n",
    "ax.set_xlabel('Read Cycle Bin')\n",
    "ax.set_ylabel('Weighted QErrAvg (Phred)')\n",
    "ax.legend(title=\"ScoreBins (0-3)\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.xticks(range(cyc_rt2_stat_df[CYC_RT2.CYC_BIN_COL].min(), cyc_rt2_stat_df[CYC_RT2.CYC_BIN_COL].max()+1,2))\n",
    "# plt.yticks(range(round(cyc_rt2_stat_df[RT2_STAT.QLTY_ERR_AVG_COL].min()), round(cyc_rt2_stat_df[RT2_STAT.QLTY_ERR_AVG_COL].max())+1))\n",
    "# display the chart\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
